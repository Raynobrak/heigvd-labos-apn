{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bb73daa",
   "metadata": {},
   "source": [
    "<img src=\"https://heig-vd.ch/docs/default-source/doc-global-newsletter/2020-slim.svg\" alt=\"Logo HEIG-VD\" style=\"width: 80px;\" align=\"right\"/>\n",
    "\n",
    "# Cours APN - Labo 6 : Autoencodeurs et détection de fraudes\n",
    "\n",
    "## Résumé\n",
    "Le but de ce laboratoire est d'entraîner des autoencodeurs sur des données de transactions bancaires, en mode non supervisé.  La fonction de coût sera la capacité de l'autoencodeur à reproduire en sortie les données d'entrée.  Trois réseaux de neurones autoencodeurs seront testés.\n",
    "\n",
    "Ensuite, on considérera que les données mal reconstruites sont atypiques, et on testera l'hypothèse qu'il s'agit de transactions frauduleuses.  On utilisera donc cette information pour évaluer la capacité de l'autoencodeur à détecter les fraudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c37de1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras # pour l'installation, \"pip install tensorflow\" suffira"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da82dfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import PrecisionRecallDisplay, average_precision_score\n",
    "from sklearn.metrics import RocCurveDisplay, roc_auc_score\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5768fa",
   "metadata": {},
   "source": [
    "## 1. Données : source\n",
    "\n",
    "Vous utiliserez un jeu de données fourni par le [Groupe ML de l'Université Libre de Bruxelles](http://mlg.ulb.ac.be/), disponible sur Kaggle : https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud.  Pour simplifier, une version vous est fournie sur Switchdrive dans un fichier [creditcard.zip](https://drive.switch.ch/index.php/s/lBqMRsADWrU2S4R).  Voici la description des données par les auteurs :\n",
    "\n",
    "> The dataset contains transactions made by credit cards over two days in September 2013 by European cardholders.  It contains only numerical input variables which are the result of a PCA transformation (due to confidentiality issues).  Features V1, ..., V28 are the principal components.  Two features were not transformed: 'Time' (seconds since the 1st transaction) and 'Amount'.  \n",
    "\n",
    "> The feature 'Class' takes value 1 in case of a fraudulent transaction and 0 otherwise.  There are 492 frauds out of 284,807 transactions (0.17%).  As the dataset is highly unbalanced, we recommend measuring the accuracy using the Area Under the Precision-Recall Curve (AUPRC), not with confusion matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c067680e",
   "metadata": {},
   "source": [
    "## 1. Charger et préparer les données\n",
    "a. Chargez les données de `creditcard.csv` directement dans une *dataframe* Pandas appelée `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95608069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e620951",
   "metadata": {},
   "source": [
    "b. Affichez quelques informations sur ces données et leurs caractéristiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a7bc3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c0f164e",
   "metadata": {},
   "source": [
    "c. Construisez une nouvelle *dataframe* appelée `data_labels` contenant seulement l'attribut qui indique si une transaction est frauduleuse ou non (attribut `Class`).  Supprimez les attributs `Time` et `Class` de la *dataframe* initiale `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e9478f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14696b88",
   "metadata": {},
   "source": [
    "d. Normalisez toutes les colonnes de `data` vers des valeurs de moyenne nulle et d'écart-type égal à 1 (distribution centrée réduite). Utilisez pour cela le `StandardScaler` de scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6845bc63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ebf47400",
   "metadata": {},
   "source": [
    "e. Pourquoi est-il acceptable ici de ne pas diviser `data` en données d'entraînement et de test ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12aeab4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2487bf4a",
   "metadata": {},
   "source": [
    "# 2. Définir les fonctions d'évaluation du modèle\n",
    "Veuillez définir deux fonctions qui affichent :\n",
    "   1. la courbe précision-rappel et la précision moyenne (qui est aussi la valeur de retour)\n",
    "   1. la courbe ROC et l'aire sous la courbe (qui est aussi la valeur de retour)\n",
    "\n",
    "Puis, veuillez recopier leur code et écrire une fonction qui affiche les deux courbes ensemble.\n",
    "\n",
    "Ces fonctions, spécifiées ci-dessous, utilisent les classes et fonctions importées de `sklearn.metrics` au début de ce notebook.  Veuillez consulter leur documentation pour savoir comment les utiliser.\n",
    "\n",
    "Une fonction auxiliaire vous est donnée, qui mesure l'erreur de reconstruction entre les données d'origine et celles reconstruites par un autoencodeur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fd97a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruction_error(X_orig, X_pred):\n",
    "    '''\n",
    "    Mesure l'erreur de reconstruction pour l'ensemble des données (compare 2 dataframes).\n",
    "    Retourne une série avec l'erreur de chaque point de données.\n",
    "    '''\n",
    "    loss = np.sum((np.array(X_orig) - np.array(X_pred))**2, axis=1) # carré de l'erreur pour chaque item\n",
    "    loss = pd.Series(data = loss, index = X_orig.index) # transformer en Series\n",
    "    loss = (loss - np.min(loss)) / (np.max(loss) - np.min(loss)) # normalisation sur tous les items vers [0, 1]\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f43631",
   "metadata": {},
   "source": [
    "Veuillez écrire une fonction pour afficher la courbe précision-rappel et retourner la précision moyenne.  Veuillez écrire une fonction pour afficher la courbe ROC.  Enfin, veuillez copier le code dans une fonction qui affiche les deux courbes ensemble.  Les paramètres des fonctions sont les étiquettes correctes, les valeurs des erreurs de reconstruction, et en option les valeurs prédites par une méthode baseline, affichant ainsi deux courbes si elles sont fournies.  Leurs valeurs de retour sont respectivement la précision moyenne et l'aire sous la courbe ROC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e356a32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_pr_curve(labels, rec_errors, baseline=[]):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6d3b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_roc_curve(labels, rec_errors, baseline=[]):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555145d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_pr_roc(labels, rec_errors, baseline=[]):\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b955072f",
   "metadata": {},
   "source": [
    "## 3. Tester des modèles *baseline*\n",
    "\n",
    "On considère deux modèles *baseline* pour des valeurs de reconstruction:\n",
    "   1. des scores aléatoires dans [0, 1] pour chaque item : `np.random.rand(data.shape[0])`\n",
    "   1. la norme L2 du vecteur d'attributs de chaque transaction, normalisée par colonne entre 0 et 1, qui peut être obtenue simplement ainsi avec la fonction définie plus haut : `reconstruction_error(data, np.zeros(data.shape[0]))`\n",
    "   \n",
    "Veuillez afficher les courbes précision-rappel et ROC pour ces deux *baselines* en même temps, grâce à la fonction précédente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7aeb6d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "715507ec",
   "metadata": {},
   "source": [
    "Sachant que les données proviennent d'une transformation PCA des données de transaction originales (auxquelles nous n'avons pas accès), pouvez-vous tenter d'expliquer le score non-nul obtenu par la 2e baseline ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a21a67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5f6ee3a",
   "metadata": {},
   "source": [
    "## 4. Définir des fonctions pour entraîner, valider, et évaluer des modèles\n",
    "\n",
    "Veuillez définir une fonction `train` qui entraîne un *modèle* (que vous créerez plus bas avec Keras) sur un jeu de *données*, avec l'objectif de reconstruire les données (donc les données d'entrée et de sortie pour un entraînement supervisé sont identiques).  Toutes les *x* époques d'entraînement (`epochs_per_iteration`) la fonction `train` affiche les scores de *précision moyenne* et de *aire sous la courbe ROC*, mais pas les graphiques.  La fonction itère cela *y* fois (`nb_iterations`).\n",
    "\n",
    "Veuillez définir aussi une fonction `evaluate` qui affiche les courbes précision-rappel et ROC pour un modèle, et inclut dans chaque graphique la *baseline* de la norme L2 des données initiales (2e baseline de la section 3).\n",
    "\n",
    "Vous pouvez utiliser ces [méthodes de Keras](https://keras.io/api/models/model_training_apis) :\n",
    "   * [model.fit(...)](https://keras.io/api/models/model_training_apis/#fit-method) pour lancer un certain nombre de pas d'entraînement (*backward pass*)\n",
    "   * [model.predict(...)](https://keras.io/api/models/model_training_apis/#predict-method) pour exécuter le modèle sur des données et obtenir la sortie (*forward pass*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f40f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, epochs_per_iteration = 10, nb_iterations = 10):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a231cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data, data_labels):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec691f74",
   "metadata": {},
   "source": [
    "## 5. Créer, entraîner et évaluer des autoencodeurs \n",
    "\n",
    "### 5.1. Autoencodeur simple à trois couches\n",
    "\n",
    "Veuillez définir en Keras un autoencodeur à trois couches, avec une couche de codage ayant une dimension plus faible que celle d'entrée (*undercomplete autoencoder*).  Utiliser un modèle de type `Sequential()` avec des couches entièrement connectées de type `Dense()`, en vous guidant sur les [exemples de Keras](https://keras.io/api/models/sequential/).  Choisissez une fonction de coût (*loss*) et un optimiseur appropriés.  N'oubliez pas de [compiler le modèle](https://keras.io/api/models/model_training_apis/#compile-method) à la fin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693f0ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c9d388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('modele_1.h5')  # enregistrer le modèle\n",
    "# del model  # supprimer le modèle de la mémoire\n",
    "# model = keras.models.load_model('modele_1.h5') # charger le modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c7a590",
   "metadata": {},
   "source": [
    "Veuillez entraîner le modèle avec la fonction `train` que vous avez définie plus haut.  Selon vos résultats intermédiaires, écrivez ici la commande qui semble suffisante pour atteindre le maximum de performance, et affichez ses résultats.  Notez que le modèle est sauvegardé, donc plusieurs appels à `train` permettent de continuer l'entraînement.  Dans votre rapport final, indiquez explicitement la durée totale en nombre d'époques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3c8137",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, data, 20, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafa73b3",
   "metadata": {},
   "source": [
    "Veuillez afficher les deux courbes (y compris les *baselines*), et les scores du modèle avec la fonction `evaluate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cb2e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, data, data_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6d22d1",
   "metadata": {},
   "source": [
    "**Veuillez discuter vos résultats.**  Comment jugez-vous la capacité du modèle à détecter des transactions frauduleuses, compte tenu du fait qu'il n'a jamais été entraîné de manière supervisée ?  Comment se compare-t-il avec la baseline ?  Quelle est sa précision maximale, et pour quel rappel est-elle atteinte ?  (Approximativement, d'après le graphique.)  Comment interprétez-vous ces valeurs ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba05dd7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "788c4450",
   "metadata": {},
   "source": [
    "### 5.2. Autoencodeur à cinq couches\n",
    "\n",
    "Veuillez définir maintenant un autoencodeur à cinq couches, sur le même principe que le précédent, toujours *undercomplete*.  Effectuez son entraînement et son évaluation finale, comme pour le modèle à 3 couches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb54cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c65a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, data, 10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff966e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('modele_2.h5')  # enregistrer le modèle\n",
    "# del model  # supprimer le modèle de la mémoire\n",
    "# model = keras.models.load_model('modele_1.h5') # charger le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97704c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, data, data_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c9f29d",
   "metadata": {},
   "source": [
    "Veuillez discuter vos résultats et les comparer avec les précédents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07997e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a03026d3",
   "metadata": {},
   "source": [
    "### 5.3. Autoencodeur à trois couches, *overcomplete*, avec *sparsity*\n",
    "Veuillez enfin définir un autoencodeur à trois couches, mais avec une couche cachée ayant une dimension supérieure à celle des couches d'entrée et de sortie.  Afin d'éviter la pure copie entrée/sortie, ajoutez une contrainte de régularisation sur la couche cachée, qui limite la somme des valeurs absolues des activations dans cette couche (voir la [documentation](https://keras.io/api/layers/regularizers/) de Keras)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039a0eea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93b5795",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, data, 10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a954c5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('modele_3.h5')  # enregistrer le modèle\n",
    "# del model  # supprimer le modèle de la mémoire\n",
    "# model = keras.models.load_model('modele_1.h5') # charger le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e5b7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, data, data_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d607dc98",
   "metadata": {},
   "source": [
    "Veuillez discuter vos résultats et les comparer avec les précédents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b619ed",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c03a6c6f",
   "metadata": {},
   "source": [
    "### Fin du laboratoire 6\n",
    "Veuillez nettoyer le *notebook* et y inclure l'affichage des résultats de vos systèmes définitifs.  Ne pas effacer les logs d'entraînement et les graphiques.  Veuillez ensuite soumettre le *notebook* sur Cyberlearn."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_apn",
   "language": "python",
   "name": "conda_apn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
