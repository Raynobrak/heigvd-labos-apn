{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://heig-vd.ch/docs/default-source/doc-global-newsletter/2020-slim.svg\" alt=\"Logo HEIG-VD\" style=\"width: 80px;\" align=\"right\"/>\n",
    "\n",
    "# Cours APN - Labo 8 : Recommandation de films par filtrage collaboratif\n",
    "\n",
    "## Résumé\n",
    "\n",
    "Le but de ce laboratoire est d'entraîner et de tester plusieurs méthodes de recommandation par filtrage collaboratif :\n",
    "* plusieurs *baselines* (notes moyennes par utilisateur ou par film)\n",
    "* deux approches *memory-based* (modèle utilisateur-utilisateur ou film-film)\n",
    "* une approche *model-based* (réduction de dimensionnalité)\n",
    "\n",
    "Un jeu de données d'entraînement est fourni, ainsi qu'un jeu de validation, sur lequel vous pourrez tester vos méthodes et choisir les paramètres donnant les meilleurs résultats.\n",
    "\n",
    "**Pour rendre ce travail,** veuillez répondre aux questions en écrivant le code demandé, résumer les tests effectués, et comparer entre eux les scores obtenus.  Veuillez ensuite rendre le notebook sur Cyberlearn.\n",
    "\n",
    "**Pour participer à la compétition**, veuillez rendre séparément sur Cyberlearn un notebook qui permet d'exécuter seulement votre meilleure méthode sur les données de validation (nous les remplacerons par celles de test) ; veuillez rendre également le modèle qui est utilisé par votre notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import mean_squared_error # fournit aussi la RMSE\n",
    "from tqdm import tqdm # permet d'afficher la progression de l'exécution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Analyse exploratoire des données\n",
    "\n",
    "Le groupe de recherche GroupLens met à disposition le [jeu de données MovieLens](http://files.grouplens.org/datasets/movielens/) contenant 20 millions de *ratings*, c'est-à-dire des notes données à des films par des utilisateurs.  Pour simplifier, deux extraits des données sont fournis dans les fichiers `ratings_train.csv` et `ratings_valid.csv` sur Cyberlearn.  \n",
    "\n",
    "Ces fichiers contiennent les index originaux des utilisateurs et des films, ainsi que des index nouveaux (*new*) qui vont de 1 à `n_users` et de 1 à `n_movies` sans discontinuer. \n",
    "\n",
    "Note : GroupLens fournit aussi d'autres informations, notamment une correspondance entre les index originaux des films et leurs titres.  En revanche, les utilisateurs sont toujours anonymisés et sont désignés par leurs index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1a.** Veuillez charger les deux extraits de données dans deux *dataframes* appelées `train_df` et `valid_df`.\n",
    "* Veuillez afficher les 3 premières lignes de chacune.\n",
    "* Combien de *ratings* contient chacune des *dataframes* ?\n",
    "* Quels sont les valeurs minimale, maximale, et moyenne des *ratings* dans chaque *dataframe* ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1b. Vérifications.** Quelles sont les plus petites et les plus grandes valeurs des *nouveaux* index des utilisateurs et des films, dans chacune des deux dataframes ?  Combien de valeurs différentes y a-t-il ? Est-ce qu'il y a des index manquants ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1c.** Veuillez d'abord définir les variables `n_users` et `n_movies` qui stockent le nombre d'utilisateurs et de films différents.  Quel est le nombre moyen de *ratings* par utilisateur ?  Et par film ?\n",
    "\n",
    "Dans `train_df`, combien de *ratings* possède le film le plus souvent évalué ?  (Autrement dit, quel est le nombre maximal de *ratings* d'un film ?)  Combien de *ratings* possède le film le moins souvent évalué ?  \n",
    "\n",
    "Indication : pour calculer le nombre de ratings par film, appliquer `groupby()` puis `count()` sur la *dataframe*. \n",
    "\n",
    "Dans `train_df`, combien de *ratings* a formulé l'utilisateur qui s'est le plus souvent exprimé ?  (Autrement dit, quel est le nombre maximal de *ratings* donnés par un utilisateur ?)  Combien de *ratings* a formulé l'utilisateur qui s'est le moins souvent exprimé ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_users =\n",
    "# n_movies =\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1d (facultatif).** Le but ici est de mieux étudier la distribution des *ratings* par utilisateur, dont vous venez de calculer les valeurs moyenne, minimale et maximale.\n",
    "\n",
    "Veuillez afficher (côte à côte si possible) les histogrammes du nombre de *ratings* par utilisateur dans `train_df` et dans `valid_df`.  Pensez à bien écrire les légendes des axes. Qu'observe-t-on en comparant `train_df` et dans `valid_df`?\n",
    "\n",
    "Même question pour le nombre de *ratings* par film."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1e.** Veuillez générer les matrices *utilisateurs x films* qui contiennent dans chaque cellule \\[i, j\\] le *rating* de l'utilisateur *i* pour le film *j*.  Si ce *rating* n'existe pas, la cellule vaut zéro.  Veuillez générer :\n",
    "- la matrice `train_matrix` à partir de `train_df`\n",
    "- la matrice `valid_matrix` à partir de `valid_df`\n",
    "\n",
    "Quel est le taux de remplissage (cellules non nulles) de chaque matrice ?  On peut le calculer soit à partir des *dataframes*, soit directement sur les matrices.  Que pouvez-vous observer en comparant ces deux valeurs ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Évaluation des systèmes \"baseline\"\n",
    "\n",
    "Dans cette section, vous allez créer plusieurs systèmes *baseline* pour la comparaison, calculer leurs scores sur `valid_matrix` et les afficher.  Le calcul des scores vous est montré au point 2a.  Ces systèmes sont :\n",
    "- **2a.** Prédiction des *ratings* comme valeurs aléatoires entre 1 et 10 (**code fourni**).\n",
    "- **2b.** Prédiction des *ratings* par la moyenne de tous les *ratings* fournis dans `train_matrix`.\n",
    "- **2c.** Prédiction des *ratings* d'un utilisateur par la moyenne de ses *ratings* fournis dans `train_matrix`.\n",
    "- **2d.** Prédiction des *ratings* d'un film par la moyenne de ses *ratings* fournis dans `train_matrix`.\n",
    "- **2e.** Prédiction de votre choix, par une combinaison des éléments de (b), (c) et (d)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2a. Voici comment calculer la Root Mean Squared Error (RMSE) des prédictions par rapport aux ratings de valid_matrix.\n",
    "\n",
    "valid_vector = valid_matrix[valid_matrix.nonzero()] # suite des ratings non-nuls de valid_matrix\n",
    "\n",
    "predict_2a = np.random.randint(1, 11, (len(valid_vector), 1)) # ratings aléatoires pour les utilisateurs x films \n",
    "\n",
    "rmse_2a = mean_squared_error(valid_vector, predict_2a, squared=False) # 'False' pour avoir la RMSE\n",
    "\n",
    "print(f'RMSE en faisant des prédictions aléatoires entre 1 et 11 : {round(rmse_2a, 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2b -- veuillez écrire votre code ici et afficher le score RMSE\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2c -- veuillez écrire votre code ici et afficher le score RMSE\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2d -- veuillez écrire votre code ici et afficher le score RMSE\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2e -- veuillez écrire votre code ici et afficher le score RMSE\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2f.** Veuillez recopier ici les scores obtenus et commenter leurs différences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Filtrage collaboratif basé sur les exemples : modèle utilisateur-utilisateur\n",
    "\n",
    "Dans cette partie, vous allez implémenter et tester les modèles de filtrage collaboratif *\"memory-based\"* qui calculent les *ratings* prédits pour chaque utilisateur selon les films les plus appréciés par les utilisateurs semblables.  Les formules pour ce modèle ont été données en cours.  Il faudra faire attention aux sous-ensembles sur lesquels sont calculées les différentes sommes.\n",
    "\n",
    "**3a.** Veuillez calculer les *ratings* moyens de chaque utilisateur et les stocker dans un tableau nommé `mean_user_ratings`.\n",
    "\n",
    "Attention, il ne faut pas inclure les valeurs nulles dans le calcul de ces moyennes.  Les zéros ne sont pas de vrais scores (*ratings*) mais indiquent l'absence de score.  Si on les incluait, les moyennes seraient toutes très basses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_user_ratings = ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3b.** *Memory-based collaborative filtering: user-user model.*  Veuillez implémenter la formule vue en cours pour calculer la matrice `sim`.  Il s'agit d'un coefficient de similarité entre deux utilisateurs, sur la base des *ratings* qu'ils ont formulés pour les films qu'ils ont jugés en commun.  On utilise la corrélation de Pearson, mais restreinte aux films communs, c'est-à-dire ceux avec des *ratings* non nuls des deux utilisateurs.  Pour cette raison, on ne peut pas appliquer directement la fonction `numpy.corrcoef()` sur `train_matrix`, mais on doit effectuer le calcul explicitement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation de la matrice des similarités entre utilisateurs :\n",
    "# sim[i, j] mesure la similarité entre les utilisateurs i et j.\n",
    "# La matrice sera symétrique car sim[i, j] = sim[j, i], et elle peut\n",
    "# avoir la diagonale nulle, car le modèle n'utilisera pas sim[i, i].\n",
    "\n",
    "sim = np.zeros((n_users, n_users)) \n",
    "\n",
    "# Parcourir les ratings des utilisateurs i et j (avec i<j), c'est-à-dire \n",
    "# train_matrix[i] et train_matrix[j], retenir seulement les positions où\n",
    "# les deux ratings sont >0, puis calculer le coefficient de corrélation.\n",
    "\n",
    "for i in tqdm(range(n_users)):\n",
    "    for j in range(i+1, n_users):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Une fonction auxiliaire utile.  Elle retourne une copie du vecteur \n",
    "# qui garde ses n plus grandes valeurs et met les autres à zéro.\n",
    "def highest(array, n):\n",
    "    if n >= len(array) or n<0:\n",
    "        return array.copy()\n",
    "    else:\n",
    "        threshold = sorted(array, reverse=True)[n-1]\n",
    "        result = array.copy()\n",
    "        result[result<threshold]=0\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test de la fonction : retourne une copie de arr1 qui garde seulement\n",
    "# ses 2 plus grands éléments, puis la même chose mais en gardant les\n",
    "# deux plus grands éléments qui se trouvent à des emplacements non nuls\n",
    "# de arr2 (cet exemple servira au 3c).\n",
    "arr1 = np.array([1, 2, 5, 0, 9, 7])\n",
    "arr2 = np.array([3, 0, 2, 0, 0, 7])\n",
    "print(arr1, highest(arr1, 2), arr1)\n",
    "print(arr1, highest(arr1 * np.where(arr2 > 0, 1, 0), 2), arr1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3c.** Veuillez calculer les *ratings* prédits par le système pour tous les utilisateurs et les items (comme au 2c et 2d mais chaque cellule doit être calculée avec la formule vue en cours).  Essayez d'optimiser le nombre d'utilisateurs semblables que vous retenez dans la formule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_3 = np.zeros((n_users, n_movies)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3d.** Veuillez évaluer les *ratings* prédits en les comparant avec les *ratings* fournis par `valid_vector` calculé plus haut.  Comment se compare le résultat avec les scores du 2f ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Filtrage collaboratif basé sur les exemples : modèle film-film\n",
    "\n",
    "Dans cette partie, vous allez implémenter et tester les modèles de filtrage collaboratif *\"memory-based\"* qui calculent les *ratings* prédits pour un film selon les utilisateurs qui ont le plus apprécié les films semblables (modèle réciproque du précédent).  Les formules pour ce modèle ont été données en cours.  Il faudra faire attention aux sous-ensembles sur lesquels sont calculées les différentes sommes.\n",
    "\n",
    "**4a.** Veuillez calculer les *ratings* moyens de chaque film et les stocker dans un tableau nommé `mean_movie_ratings`.  \n",
    "\n",
    "Attention, il ne faut pas inclure les valeurs nulles dans le calcul de ces moyennes.  Les zéros ne sont pas de vrais scores (*ratings*) mais indiquent l'absence de score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_item_ratings = ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4b.** *Memory-based collaborative filtering: item-item model.*  Veuillez implémenter la formule vue en cours pour calculer la matrice `sim_item`.  Il s'agit d'un coefficient de similarité entre deux films (items), sur la base des *ratings* qu'ils ont reçus des utilisateurs qui se sont exprimés sur les deux films.  On utilise la corrélation de Pearson, mais restreinte aux utilisateurs communs, c'est-à-dire ceux avec des *ratings* non nuls des deux films.  Pour cette raison, on ne peut pas appliquer directement la fonction `numpy.corrcoef()` sur `train_matrix`, mais on doit effectuer le calcul explicitement.  Le code est très similaire au point 3b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation de la matrice des similarités entre films :\n",
    "# sim_item[i, j] mesure la similarité entre les films i et j.\n",
    "# La matrice sera symétrique car sim[i, j] = sim[j, i], et elle peut\n",
    "# avoir la diagonale nulle, car le modèle n'utilisera pas sim[i, i].\n",
    "sim_item = np.zeros((n_movies, n_movies)) \n",
    "\n",
    "# Parcourir les ratings des films i et j (avec i<j), c'est-à-dire \n",
    "# train_matrix[:,i] et train_matrix[:,j], retenir seulement les positions où\n",
    "# les deux ratings sont >0, puis calculer le coefficient de corrélation.\n",
    "\n",
    "for i in tqdm(range(n_movies)):\n",
    "    for j in range(i,n_movies):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4c.** Veuillez calculer les *ratings* prédits par le système pour tous les utilisateurs et les items (analogue au 3c).  Essayez d'optimiser le nombre d'films semblables que vous utilisez dans la formule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_4 = np.zeros((n_users, n_movies))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4d.** Veuillez évaluer les *ratings* prédits en les comparant avec les *ratings* fournis par `valid_vector` calculé plus haut.  Comment se compare le résultat avec les scores du 2f et ceux du 3d ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Filtrage collaboratif par factorisation de matrices\n",
    "\n",
    "Dans cette section, vous allez mettre en place un modèle de prédiction des *ratings* utilisant la factorisation de matrices, comme vu en cours.  Vous calculerez deux matrices U et V, telles que R = U.T x V où R est la matrice des *ratings* (U.T désigne la transposée de U).  Le calcul direct d'une SVD ne fonctionne pas, car la matrice R (ici, `train_matrix`) contient beaucoup de 0 qui signifient en réalité des *ratings* inconnus.  Vous utiliserez comme données d'entraînement directement celles de `train_df`. \n",
    "\n",
    "L'hyperparamètre à régler est la dimension réduite de U et de V, notée `n_latent_factors`.\n",
    "\n",
    "Vous utiliserez une approche par descente de gradient, implémentée en Keras, qui utilisera seulement les *ratings* connus (non nuls) pour s'entraîner.  Après avoir calculé U et V, vous pourrez estimer toutes les valeurs inconnues de R, puisque R = U.T x V -- il suffira pour cela d'utiliser le modèle en mode prédiction.\n",
    "\n",
    "Vous évaluerez le résultat en comparant ces estimations avec les *ratings* connus de `valid_df`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, dot\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5a.** Veuillez définir le modèle Keras qui prend en entrée l'index de l'utilisateur et l'index du film, et produit en sortie le *rating* estimé comme le produit scalaire des embeddings des entrées (*voir le cours*).  Finir par la compilation du modèle selon la ligne de code fournie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition du modèle\n",
    "# n_latent_factors = \n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=[RootMeanSquaredError()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5b.** Veuillez entraîner le modèle pendant un certain nombre d'époques et sauvegarder l'historique des scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5c.** Veuillez afficher sur un graphique l'évolution de la RMSE sur les données de validation (`valid_df`) au cours de l'entraînement.  Veuillez afficher aussi séparément la meilleure valeur de RMSE.  Après plusieurs expériences, veuillez laisser un graphique qui montre que l'apprentissage est satisfaisant et expliquer pourquoi. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5d.** Effectuez plusieurs expériences et décrivez-les brièvement ici, pour déterminer votre meilleur modèle -- c'est à dire les valeurs optimales de `n_latent_factors` et du nombre d'époques.  Utilisez comme critère la RMSE sur les données de validation.  Si ce modèle est meilleur que ceux du (3) ou du (4), veuillez le sauvegarder à l'aide de la fonction [save](https://keras.io/guides/serialization_and_saving/) de Keras pour le soumettre à la compétition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fin du Labo 8.**  Veuillez nettoyer ce notebook, afficher les résultats et les commentaires demandés, l'enregistrer, et le soumettre comme devoir sur Cyberlearn.  \n",
    "\n",
    "Ne pas oublier de soumettre également votre meilleur système avec le code nécessaire pour l'évaluer sur des données de test similaires à celles de validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_apn",
   "language": "python",
   "name": "conda_apn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
