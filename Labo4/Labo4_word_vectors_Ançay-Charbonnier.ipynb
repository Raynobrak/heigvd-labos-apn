{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac5975ff",
   "metadata": {},
   "source": [
    "<img src=\"https://heig-vd.ch/docs/default-source/doc-global-newsletter/2020-slim.svg\" alt=\"Logo HEIG-VD\" style=\"width: 80px;\" align=\"right\"/>\n",
    "\n",
    "# Cours APN - Labo 4 : Visualisation de vecteurs de mots\n",
    "\n",
    "## Résumé\n",
    "Le but de ce laboratoire est de visualiser des vecteurs de mots grâce à des méthodes de réduction de dimensionnalité.  La visualisation permettra de deviner plus facilement le \"mot du jour\" dans le jeu en ligne [Cémantix](https://cemantix.certitudes.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b142169f",
   "metadata": {},
   "source": [
    "## 1. Prise en main de word2vec\n",
    "\n",
    "Le modèle Word2vec contient des _embeddings_ des mots qui sont appris automatiquement à partir de textes.  Chaque mot est donc représenté par un vecteur dans un espace avec plusieurs centaines de dimensions (p.ex. 300 ou 500).  Dans cet espace, les mots de sens ou d'usage proches ont des vecteurs proches (les _embeddings_ capturent la similarité entre mots).  Mais la dimensionnalité de l'espace fait qu'il est difficile de visualiser les vecteurs de mots.\n",
    "\n",
    "La librairie [Gensim](https://radimrehurek.com/gensim/index.html) permet de charger un modèle Word2vec existant (avec la fonction `load_word2vec_format(...)`) et de manipuler les vecteurs de mots (instances de la classe `KeyedVectors`).  On peut notamment utiliser la fonction `similarity(w1, w2)` qui retourne le cosinus des vecteurs correspondant aux mots `w1` et `w2`, à condition que ceux-ci soient connus du modèle.  On peut aussi utiliser la fonction `most_similar([w])` qui retourne les mots voisins d'un ou plusieurs mots.  La [documentation de KeyedVectors](https://radimrehurek.com/gensim/models/keyedvectors.html) fournit des exemples utiles.\n",
    "\n",
    "Veuillez télécharger l'_un des deux_ modèles word2vec suivants, déjà entraînés, mis à disposition par [J.-Ph. Fauconnier](https://fauconnier.github.io/#data):\n",
    "- [frWac_no_postag_no_phrase_500_cbow_cut100.bin](https://embeddings.net/embeddings/frWac_no_postag_no_phrase_500_cbow_cut100.bin) - plus petit (229 Mo), mais pas identique au modèle utilisé pour Cémantix ;\n",
    "- [frWac_no_postag_phrase_500_cbow_cut10.bin](https://embeddings.net/embeddings/frWac_no_postag_phrase_500_cbow_cut10.bin) - bien plus grand (2 Go) donc assez gourmand en mémoire, mais qui est exactement celui utilisé pour Cémantix.\n",
    "Veuillez placer le modèle choisi dans le dossier `gensim-data` de votre dossier utilisateur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ec9fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Téléchargement, si nécessaire.\n",
    "# import wget\n",
    "# url = 'https://embeddings.net/embeddings/frWac_no_postag_no_phrase_500_cbow_cut100.bin'\n",
    "# wget.download(url, path_to_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84d558a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3711012d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_model = \"C:\\\\Users\\\\andrei\\\\gensim-data\\\\frWac\\\\frWac_no_postag_no_phrase_500_cbow_cut100.bin\" # à adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114bdda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format(path_to_model, binary=True, unicode_errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c45ba9",
   "metadata": {},
   "source": [
    "a. Choisissez deux mots de sens proches `w1` et `w2`, et un autre plus différent noté `w3`. Affichez la similarité selon word2vec (cosinus) entre chaque paire de mots.  Ces valeurs correspondent-elles à vos intuitions ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7170b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ac52e3",
   "metadata": {},
   "source": [
    "b. Affichez les 10 mots les plus proches de `w1` selon word2vec avec pour chacun sa similarité avec `w1`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0919678c",
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e763f4aa",
   "metadata": {},
   "source": [
    "c. Quels sont les 15 premiers coefficients du vecteur (_embedding_) du mot `w1` ? Quelle est la dimension de ce vecteur ?  Quelle est la taille du vocabulaire connu du modèle ?  Vous pouvez simplement écrire les commandes répondant à ces questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a373edde",
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136d3ca3",
   "metadata": {},
   "source": [
    "d. Veuillez écrire une fonction appelée `neighbors` selon les spécifications suivantes.  Cette fonction servira plus loin pour l'affichage.\n",
    "* input : modèle, liste de mots, nombre de voisins (`topn`) ;\n",
    "* output : liste de mots voisins de chacun des mots de l'input, représentés par un dictionnaire expliqué ci-après ;\n",
    "* fonctionnement : pour _chacun_ des mots donnés en input, la fonction teste si le mot est dans le vocabulaire du modèle word2vec (sinon elle ne le considère pas), puis demande au modèle la liste des `topn` mots voisins ; pour chacun de ces mots, la fonction construit un `dict` à 4 champs : \n",
    "  - mot voisin\n",
    "  - similarité\n",
    "  - mot de départ\n",
    "  - code de couleur associé au mot de départ : 1, 2, etc.\n",
    "\n",
    "**Exemple** : si on appelle la fonction avec \\['école'\\], le début du résultat sera :\n",
    "```\n",
    "[{'neighbor': 'scolaire',\n",
    "  'similarity': 0.7114928364753723,\n",
    "  'ref_word': 'école',\n",
    "  'color_code': 1}, ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b01480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neighbors(model, word_list, topn = 5):\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cd119b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tester avec cet appel :\n",
    "print(neighbors(model, ['chat', 'étudier'], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d19cd5",
   "metadata": {},
   "source": [
    "## 2. Affichage simple des voisins d'un mot\n",
    "\n",
    "Pour commencer, veuillez étudier et exécuter le code fourni en exemple : `Labo4_plotly.ipynb`.  Cela vous montrera comment utiliser l'affichage 2D/3D avec `plotly.js`, et vous permettra de traiter les questions suivantes.\n",
    "\n",
    "Veuillez écrire et exécuter une fonction qui effectue les opérations suivantes, étant donné un mot en entrée :\n",
    "* obtenir les vecteurs word2vec du mot et de ses `topn` plus proches voisins ;\n",
    "* transformer ces vecteurs en 2D par l'ACP ;\n",
    "* afficher en 2D chaque points correspondant à un mot, avec comme étiquette le mot lui-même.\n",
    "\n",
    "**Notes:** cette fonction sert de version préliminaire à une fonction plus générique demandée ci-dessous.  Il n'est pas demandé de distinguer le mot entré des mots voisins, dans l'affichage (même type de points).  Il n'est pas nécessaire pour l'instant d'utiliser la fonction `neighbors`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35a4625",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd4156a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_PCA_2D_neighbors(model, word, topn = 5):\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba143b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher le mot 'chat' et ses 20 plus proches voisins\n",
    "# projetés en deux dimensions avec PCA (test de la fonction).\n",
    "display_PCA_2D_neighbors(model, 'précis', 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f594e0",
   "metadata": {},
   "source": [
    "## 3. Affichage configurable des voisins de plusieurs mots\n",
    "\n",
    "Le but maintenant est d'écrire une fonction `display_dimred_neighbors` qui affiche sur un seul graphique les mots voisins de chaque mot d'une liste de mots donnés.  Vous utiliserez ici la fonction auxiliaire `neighbors` définie plus haut  Les paramètres suivants seront passés à la fonction `display_dimred_neighbors` :\n",
    "\n",
    "* `model` - le nom du modèle word2vec\n",
    "* `word_list` - liste de mots dont on veut afficher les voisins (s'ils existent dans `model`)\n",
    "* `n_components` - dimensionnalité de l'affichage, 2 ou 3\n",
    "* `topn` - nombre de voisins à afficher pour chaque mot \n",
    "* `method` - **méthode de réduction de dimensionnalité : pca, mds, isomap, tsne, ou umap**\n",
    "* `n_neighbors`- nombre de voisins considérés par la méthode (applicable à isomap, umap, et tsne (appelé alors `perplexity`)).\n",
    "\n",
    "Trois tests sont demandés à la question 4, mais vous pouvez en exécuter d'autres et les inclure ici."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcd5af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.manifold import Isomap\n",
    "from sklearn.manifold import TSNE\n",
    "from umap import UMAP # Attention, installer le module nommé 'umap-learn' (avec conda install)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c9d33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_dimred_neighbors(model, word_list, n_components = 3, topn = 5, method = 'pca', n_neighbors = 5):\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bab949",
   "metadata": {},
   "source": [
    "## 4. Application à l'étude des mots voisins dans word2vec\n",
    "\n",
    "Veuillez choisir quatre mots (`word_list = [m1, m2, m3, m4]`) de façon à ce que m1 et m2 soient très proches par leur sens ou leur usage, m3 un peu plus éloigné, et m4 très éloigné.  L'objectif de cette question est d'étudier la distribution des mots voisins de ces quatre mots (entre 10 et 50) par une visualisation en 2D ou en 3D des vecteurs de mots.  \n",
    "\n",
    "En expérimentant avec plusieurs configurations (méthode de réduction de dimensionnalité, valeur de `n_neighbors`, nombre de voisins `topn`), veuillez répondre aux questions suivantes, à l'aide d'un ou plusieurs graphiques par question :\n",
    "\n",
    "**a.** si on utilise une méthode de réduction de dimensionnalité linéaire (PCA ou MDS métrique), les quatre groupes de mots sont-ils clairement séparés dans word2vec ?\n",
    "\n",
    "**b.** si on utilise une méthode de réduction de dimensionnalité non-linéaire (Isomap, t-SNE ou UMAP), peut-on mieux mettre en évidence les quatre groupes de mots ?  Quels sont les meilleurs paramètres que vous avez trouvés permettant de bien identifier les quatre ensembles ?\n",
    "\n",
    "**c.** inversement, trouvez-vous des paramètres qui aboutissent à cinq clusters ? ou à trois ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ad49f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérer ici la liste de mots.\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6879e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 4a\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328fd322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 4b\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff07e3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 4c\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7f9433",
   "metadata": {},
   "source": [
    "## 5. Outil d'assistance pour le jeu Cémantix\n",
    "\n",
    "Le jeu en ligne [Cémantix](https://cemantix.certitudes.org/) (aussi proposé sur le site [Dictaly](https://www.dictaly.com/semantiques/))  demande de deviner le *mot du jour* en l'approchant peu à peu par des mots candidats.  Pour chacun, le système indique pour sa similarité word2vec avec le *mot du jour*, ce qui permet de se rapprocher graduellement de la solution.  Expérimentez d'abord un court instant avec le jeu 😀.\n",
    "\n",
    "L'objectif de cette question est de visualiser les voisinages de mots, pour vous aider à proposer des mots candidats et trouver plus vite la solution.  La procédure est la suivante :\n",
    "* essayez trois mots au hasard dans Cémantix\n",
    "* affichez 20-30 mots voisins de ces trois mots grâce à la fonction `display_dimred_neighbors`\n",
    "* à l'aide des mots affichés, essayez des mots candidats dans Cémantix\n",
    "* changez l'affichage en remplaçant les trois mots par de meilleurs mots\n",
    "* continuez jusqu'à trouver le *mot du jour*\n",
    "\n",
    "**Notes**\n",
    "* si vous le souhaitez, vous pouvez utiliser le modèle word2vec identique à celui de Cémantix, qui est frWac_no_postag_phrase_500_cbow_cut10.bin fourni par [J.-Ph. Fauconnier](https://fauconnier.github.io/#data)\n",
    "* ce modèle fait environ 2.3 Go et contient aussi des expressions de plusieurs mots (séparés par '_')\n",
    "* vous pouvez choisir d'utiliser le petit ou le grand modèle, sachant qu'avec le premier, les suggestions sont moins pertinentes\n",
    "* Cémantix ignore les expressions de plusieurs mots présentes dans le grand modèle -- vous pouvez choisir de le faire ou non."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acf3589",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# candidate_words = ['homme', 'rouge', 'étudier']\n",
    "candidate_words = ['rendement', 'rentabilité']\n",
    "display_dimred_neighbors(model, candidate_words, n_components = 3, topn = 30, method = 'tsne')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8813d7",
   "metadata": {},
   "source": [
    "Veuillez noter ici vos observations sur la procédure, et coller un extrait montrant votre meilleure performance au jeu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88ea035",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1539000b",
   "metadata": {},
   "source": [
    "**Fin du Labo.**  Veuillez nettoyer ce notebook en gardant seulement les résultats désirés, l'enregistrer, et le soumettre comme devoir sur Cyberlearn."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_apn",
   "language": "python",
   "name": "conda_apn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
