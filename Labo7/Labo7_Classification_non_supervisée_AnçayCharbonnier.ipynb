{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "latin-founder",
   "metadata": {},
   "source": [
    "<img src=\"https://heig-vd.ch/docs/default-source/doc-global-newsletter/2020-slim.svg\" alt=\"Logo HEIG-VD\" style=\"width: 80px;\" align=\"right\"/>\n",
    "\n",
    "# Cours APN - Labo 7 : Classification non supervisée\n",
    "\n",
    "## Résumé\n",
    "Le but de ce laboratoire est de réaliser une expérience de classification non-supervisée d'articles.  L'approche se base sur des vecteurs en basse dimension (*embeddings*) qui représentent les classes, qui seront comparés avec les vecteurs en basse dimension (*embeddings*) représentant les documents.  Ces *embeddings* seront obtenus soit au modèle `word2vec`.  La méthode sera testée sur un corpus d'articles provenant de rubriques connues, ce qui permettra d'évaluer les méthodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perceived-lodging",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librairies générales\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-statement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarité entre vecteurs (mots, catégories ou textes)\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepted-prison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librairies pour l'évaluation\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "described-scanning",
   "metadata": {},
   "source": [
    "## 1. Préparation des données\n",
    "\n",
    "Vous utiliserez un corpus d'environ 200'000 articles (titres et résumés) [diponibles sur Kaggle](https://www.kaggle.com/datasets/rmisra/news-category-dataset/versions/2) (V2, 80 Mo, nécessite un login) mais dont une copie est **fournie sur Cyberlearn**.  Dans cette partie, vous allez:\n",
    "  - a. charger le corpus fourni au format JSON, l'explorer et afficher des statistiques\n",
    "  - b. définir une fonction de normalisation de textes (avec la librairie `utils.py` déjà utilisée)\n",
    "  - c. définir une fonction d'extraction des textes avec leur catégorie\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "representative-raising",
   "metadata": {},
   "source": [
    "**a.** Veuillez charger le corpus à l'aide des instructions données ci-dessous, puis afficher les statistiques suivantes :\n",
    "  * un exemple d'article\n",
    "  * nombre total d'articles\n",
    "  * nombre d'articles pour chaque catégorie (ou classe) par ordre décroissant\n",
    "  * nombre d'articles sans `headline`\n",
    "  * nombre d'articles sans `short_description`\n",
    "  * nombre d'articles dont la longueur de `headline + short_description` est inférieure ou égale à 2 caractères\n",
    "  * longueur moyenne de `headline + short_description`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aerial-integrity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter # pour calculer facilement le nombre d'articles par categorie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mineral-saturday",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus  = []\n",
    "with open('News_Category_Dataset_v2.json', mode='r', errors='ignore') as json_file:\n",
    "    for dic in json_file:\n",
    "        corpus.append(json.loads(dic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sapphire-bookmark",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aerial-gates",
   "metadata": {},
   "source": [
    "**b.** Veuillez définir une fonction de nettoyage et normalisation des textes, qui vise à réduire la diversité du vocabulaire (lemmatisation, suppression des ponctuations, nombres, ou *stopwords*, etc.).  Veuillez utiliser les fonctions fournies dans la librairie `utils.py` fournie sur Cyberlearn et déjà vue au labo 3 (groupement hiérarchique de films).  Votre fonction devra prendre en entrée un texte non-tokenisé (une chaîne de caractères) et retournera une chaîne de caractères également, mais avec tous les tokens retenus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-pottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils # fonctions de pré-traitement des textes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-drilling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "referenced-supervisor",
   "metadata": {},
   "source": [
    "**c.** Veuillez écrire une fonction qui sélectionne les articles d'une ou plusieurs catégories (données sous forme de liste, p.ex. `['MONEY', 'SCIENCE']`) et retourne leurs textes et leurs catégories.  Plus précisément :\n",
    "* la fonction retourne une liste de textes et une liste de catégories de même longueur (au texte *i* correspond la catégorie ou classe *i*)\n",
    "* le texte de chaque article est composé de son `headline` et de sa `short_description`, séparés par un point+espace\n",
    "* si `normalize=True`, la fonction normalise les textes (note : ça ne sera pas toujours souhaitable dans les expériences suivantes)\n",
    "* on ne retient dans le résultat que les textes dont la longueur finale est supérieure à 3 caractères."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secret-sport",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_texts_categories(corpus, selected_categories, normalize=True):\n",
    "\n",
    "    return texts, categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earlier-research",
   "metadata": {},
   "source": [
    "**d.** Veuillez exécuter la fonction, en appliquant la normalisation des textes, puis afficher un exemple de résultat et commenter brièvement son contenu.  Le code est donné ci-dessous, et vous devez ajouter votre commentaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "directed-attack",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_categories = ['MONEY', 'SCIENCE']\n",
    "texts, categories = select_texts_categories(corpus, selected_categories, normalize=True)\n",
    "print(\"Exemple :\", categories[142], ':', texts[142])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cdd238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre commentaire ici."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "linear-tampa",
   "metadata": {},
   "source": [
    "___\n",
    "## 2. Classification non supervisée avec des embeddings word2vec\n",
    "\n",
    "La méthode de classification proposée comporte trois étapes.  Le but de cette partie est de définir une fonction pour chacune d'elles.  Au début, une (re)prise en main de word2vec est demandée.\n",
    "* a. prise en main de word2vec\n",
    "* b. création des représentations vectorielles (*embeddings*) des classes (catégories)\n",
    "* c. création des représentations vectorielles (*embeddings*) d'un texte\n",
    "* d. classification : comparer les similarités du vecteur de texte avec les vecteurs des classes, choisir la plus similaire\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marine-trustee",
   "metadata": {},
   "source": [
    "**a.** Prise en main de word2vec.  Vous avez déjà utilisé word2vec au Labo 4 sur la visualisation de vecteurs de mots (et Cémantix) mais ici vous utiliserez un modèle pour l'anglais.  Vous pouvez consulter la [documentation de gensim sur KeyedVectors](https://radimrehurek.com/gensim/models/keyedvectors.html#what-can-i-do-with-word-vectors)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "available-partner",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "different-denial",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si le modèle n'est pas téléchargé :\n",
    "# w2v_model = gensim.downloader.load('word2vec-google-news-300')\n",
    "# S'il l'est déjà, indiquer son emplacement :\n",
    "path_to_model = \"C:\\\\Users\\\\andrei\\\\gensim-data\\\\word2vec-google-news-300\\\\word2vec-google-news-300.gz\"\n",
    "w2v_model = KeyedVectors.load_word2vec_format(path_to_model, binary=True)\n",
    "# Attention, ce modèle prend environ 5 Go en mémoire. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acknowledged-tournament",
   "metadata": {},
   "source": [
    "Veuillez afficher les mots les plus similaires selon ce modèle word2vec du mot 'science'.  Même question pour le mot 'money' (ce sont des noms de catégories).  Que pensez-vous du résultat ?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "australian-newman",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "sorted-diana",
   "metadata": {},
   "source": [
    "Basé sur les résultats précédents et vos intuitions sur les articles qu'on peut trouver dans les catégories `['SCIENCE', 'MONEY']`, veuillez indiquer ici 5 à 10 mots représentatifs de chacune de ces deux catégories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-roots",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "utility-macintosh",
   "metadata": {},
   "source": [
    "**b.** Création des représentations vectorielles des classes (catégories).\n",
    "\n",
    "Veuillez définir une fonction qui retourne un vecteur (*embedding*) word2vec pour chacune des classes d'un tableau qui est fourni en argument de la fonction.  Consignes :\n",
    "\n",
    "* la fonction retourne la moyenne des *embeddings* des mots-clés associés à chaque classe;\n",
    "* pour les classes 'SCIENCE' et 'MONEY', elle prend les mots-clés que vous avez choisis ci-dessus (au (a)) ;\n",
    "* pour les autres classes, elle demande à word2vec les `topn` voisins du nom de la classe (en minuscules) ;\n",
    "  - si `topn = 0`, on utilise seulement le nom de la classe (en minuscules) ;\n",
    "  - on suppose que le nom de la classe est connu de word2vec.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empty-pilot",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_embedding_w2v(model, category_names, topn=30):\n",
    "\n",
    "    return category_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "three-elimination",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test : affiche-t-on 'True' ?\n",
    "e1 = cat_embedding_w2v(w2v_model, ['SCIENCE'], topn=30)\n",
    "e2 = cat_embedding_w2v(w2v_model, ['TECH'],    topn=30)\n",
    "e3 = cat_embedding_w2v(w2v_model, ['TASTE'],   topn=30)\n",
    "cosine_similarity(e1, e2) > cosine_similarity(e2, e3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appropriate-journal",
   "metadata": {},
   "source": [
    "**c.** Création de la représentation vectorielle d'un texte\n",
    "\n",
    "Veuillez définir une fonction qui prend un texte (*string*) en argument et retourne un vecteur (*embedding*) qui représente le texte.  Le texte doit être découpé en mots (tokenisé), puis on doit tester si chaque mot est connu du modèle word2vec, et si oui, on récupère le *embedding* du mot.  La fonction retourne la moyenne des *embeddings*, sauf si aucun mot du texte n'est connu du modèle word2vec, auquel cas elle retourne `[]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thick-accounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "asian-plant",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_embedding_w2v(model, text):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cutting-samoa",
   "metadata": {},
   "source": [
    "**d.** Classification non supervisée d'articles avec word2vec\n",
    "\n",
    "Veuillez définir une fonction qui prend en entrée :\n",
    "* un modèle word2vec\n",
    "* une liste de textes à classifier\n",
    "* une liste de catégories définies par leur nom en majuscules (p.ex. `['SCIENCE', 'MONEY']`)\n",
    "et qui retourne le tableau avec la catégorie prédite pour chaque texte parmi les catégories données.  \n",
    "\n",
    "Pour prédire la catégorie, la fonction calcule la similarité cosinus du *embedding* du texte avec chacun des *embeddings* des catégories, et choisit la catégorie qui a la plus grande similarité.  Si le texte n'a pas de *embedding* (parce qu'aucun de ses mots n'est connu du modèle), ou si plusieurs catégories ont la même similarité, on tire au sort la catégorie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compatible-welsh",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_w2v(model, texts, selected_categories, topn = 30):\n",
    "\n",
    "    return cat_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exciting-river",
   "metadata": {},
   "source": [
    "**e.** Veuillez réaliser la classification non supervisée des articles des catégories `['SCIENCE', 'MONEY']`.  Afficher les scores obtenus et la matrice de confusion en utilisant les fonctions de `sklearn.metrics` importées au début du notebook.  Veuillez faire plusieurs essais pour optimiser les fonctions et leurs appels, et à la fin laisser votre meilleur résultat dans ce notebook.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "african-airport",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_categories = ['SCIENCE', 'MONEY']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integral-livestock",
   "metadata": {},
   "source": [
    "**f.** Veuillez réaliser une expérience de classification non supervisée sur les articles des catégories `['TECH', 'ARTS', 'COLLEGE']` en variant le paramètre `topn` de `classify_w2v` et en indiquant la meilleure valeur trouvée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "posted-coaching",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_categories = ['TECH', 'ARTS', 'COLLEGE']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agreed-elizabeth",
   "metadata": {},
   "source": [
    "**g.** Veuillez comparer les deux expériences (points (e) et (f)) en termes de scores, de valeurs optimales de `topn`, et de l'impact du nettoyage de textes.   Veuillez donner votre opinion sur la qualité de la classification non supervisée avec word2vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-silicon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "improving-drunk",
   "metadata": {},
   "source": [
    "**Fin du Labo.**  Veuillez nettoyer ce notebook en gardant seulement les résultats et les commentaires demandés, l'enregistrer, et le soumettre comme devoir sur Cyberlearn."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_apn",
   "language": "python",
   "name": "conda_apn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
